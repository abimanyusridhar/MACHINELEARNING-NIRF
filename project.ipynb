{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf93757-cf67-44c7-9bb8-71e556bbf8d7",
   "metadata": {},
   "source": [
    "# LOAD AND INSPECT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef31dc8e-c6a5-495f-8729-8582dd028277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   ranking_year ranking_category  institute_id  \\\n",
      "0          2023           Dental   IR-N-I-1441   \n",
      "1          2023           Dental   IR-N-C-7254   \n",
      "2          2023           Dental   IR-N-I-1110   \n",
      "3          2023           Dental  IR-N-C-28507   \n",
      "4          2023           Dental  IR-N-C-19320   \n",
      "\n",
      "                                      institute_name       city        state  \\\n",
      "0  Saveetha Institute of Medical and Technical Sc...    Chennai   Tamil Nadu   \n",
      "1        Manipal College of Dental Sciences, Manipal    Manipal    Karnataka   \n",
      "2                         Dr. D. Y. Patil Vidyapeeth       Pune  Maharashtra   \n",
      "3          Maulana Azad Institute of Dental Sciences      Delhi        Delhi   \n",
      "4   A.B.Shetty Memorial Institute of Dental Sciences  Mangaluru    Karnataka   \n",
      "\n",
      "   score  rank  \n",
      "0  84.08     1  \n",
      "1  77.51     2  \n",
      "2  73.08     3  \n",
      "3  70.96     4  \n",
      "4  69.21     5  \n",
      "\n",
      "Structure of the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5413 entries, 0 to 5412\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ranking_year      5413 non-null   int64  \n",
      " 1   ranking_category  5413 non-null   object \n",
      " 2   institute_id      5413 non-null   object \n",
      " 3   institute_name    5413 non-null   object \n",
      " 4   city              5413 non-null   object \n",
      " 5   state             5413 non-null   object \n",
      " 6   score             5403 non-null   float64\n",
      " 7   rank              5413 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 338.4+ KB\n",
      "None\n",
      "\n",
      "Basic statistics of the dataset:\n",
      "        ranking_year ranking_category institute_id             institute_name  \\\n",
      "count    5413.000000             5413         5413                       5413   \n",
      "unique           NaN               13         2346                       1450   \n",
      "top              NaN      Engineering  IR-O-U-0196  Aligarh Muslim University   \n",
      "freq             NaN             1200           10                         48   \n",
      "mean     2020.129134              NaN          NaN                        NaN   \n",
      "std         2.114722              NaN          NaN                        NaN   \n",
      "min      2016.000000              NaN          NaN                        NaN   \n",
      "25%      2019.000000              NaN          NaN                        NaN   \n",
      "50%      2020.000000              NaN          NaN                        NaN   \n",
      "75%      2022.000000              NaN          NaN                        NaN   \n",
      "max      2023.000000              NaN          NaN                        NaN   \n",
      "\n",
      "           city       state        score         rank  \n",
      "count      5413        5413  5403.000000  5413.000000  \n",
      "unique      435          33          NaN          NaN  \n",
      "top     Chennai  Tamil Nadu          NaN          NaN  \n",
      "freq        375        1023          NaN          NaN  \n",
      "mean        NaN         NaN    51.257458    50.469056  \n",
      "std         NaN         NaN    11.173276    40.048326  \n",
      "min         NaN         NaN    30.310000     1.000000  \n",
      "25%         NaN         NaN    43.290000    20.000000  \n",
      "50%         NaN         NaN    50.310000    42.000000  \n",
      "75%         NaN         NaN    57.200000    73.000000  \n",
      "max         NaN         NaN    94.320000   200.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'nirf_data_sets.csv'  # Ensure the path is correct\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display the structure of the dataset\n",
    "print(\"\\nStructure of the dataset:\")\n",
    "print(data.info())\n",
    "\n",
    "# Display basic statistics of the dataset\n",
    "print(\"\\nBasic statistics of the dataset:\")\n",
    "print(data.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27451d4-c4dd-4ed1-94b4-a126ae5ce1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9520843e-04bf-4089-af80-15cdc2c2ee4e",
   "metadata": {},
   "source": [
    "# CHECKING THE MISSING VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd47c18c-419a-4144-9503-9057464168b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "ranking_year         0\n",
      "ranking_category     0\n",
      "institute_id         0\n",
      "institute_name       0\n",
      "city                 0\n",
      "state                0\n",
      "score               10\n",
      "rank                 0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after handling:\n",
      "ranking_year        0\n",
      "ranking_category    0\n",
      "institute_id        0\n",
      "institute_name      0\n",
      "city                0\n",
      "state               0\n",
      "score               0\n",
      "rank                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values before handling:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values\n",
    "data = data.dropna(subset=['score'])\n",
    "\n",
    "# Check for missing values after handling\n",
    "missing_values_after = data.isnull().sum()\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(missing_values_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69c725-4edc-4a42-9e84-4d01130adc51",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b51bd4-8253-4507-bd44-775a8ce52ef4",
   "metadata": {},
   "source": [
    "\n",
    "# HANDLING MISSING VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c6050b-614d-4a8d-8b32-fbb687d235a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data.dropna(subset=['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb8b979-efdf-4b43-b23e-0a0cf13a550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values by dropping rows with missing score values\n",
    "data = data.dropna(subset=['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ddab59-128e-471f-bc26-833df4142649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ranking_year ranking_category institute_id             institute_name  \\\n",
      "count    5403.000000             5403         5403                       5403   \n",
      "unique           NaN               12         2336                       1440   \n",
      "top              NaN      Engineering  IR-O-U-0196  Aligarh Muslim University   \n",
      "freq             NaN             1200           10                         48   \n",
      "mean     2020.123820              NaN          NaN                        NaN   \n",
      "std         2.113065              NaN          NaN                        NaN   \n",
      "min      2016.000000              NaN          NaN                        NaN   \n",
      "25%      2019.000000              NaN          NaN                        NaN   \n",
      "50%      2020.000000              NaN          NaN                        NaN   \n",
      "75%      2022.000000              NaN          NaN                        NaN   \n",
      "max      2023.000000              NaN          NaN                        NaN   \n",
      "\n",
      "           city       state        score         rank  \n",
      "count      5403        5403  5403.000000  5403.000000  \n",
      "unique      435          33          NaN          NaN  \n",
      "top     Chennai  Tamil Nadu          NaN          NaN  \n",
      "freq        373        1021          NaN          NaN  \n",
      "mean        NaN         NaN    51.257458    50.552471  \n",
      "std         NaN         NaN    11.173276    40.038185  \n",
      "min         NaN         NaN    30.310000     1.000000  \n",
      "25%         NaN         NaN    43.290000    20.000000  \n",
      "50%         NaN         NaN    50.310000    42.000000  \n",
      "75%         NaN         NaN    57.200000    73.000000  \n",
      "max         NaN         NaN    94.320000   200.000000  \n"
     ]
    }
   ],
   "source": [
    "# Get descriptive statistics of the dataset, including both numerical and categorical features\n",
    "desc_stats = data.describe(include='all')\n",
    "print(desc_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9283bb-445e-4690-8cf7-16af383ac8ca",
   "metadata": {},
   "source": [
    "# Convert Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660d98ec-857a-48aa-bdb7-062b6003eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoders saved successfully.\n",
      "   ranking_year  ranking_category  institute_id  institute_name  city  state  \\\n",
      "0          2023                 3          1211            1138    70     27   \n",
      "1          2023                 3          1208             804   255     14   \n",
      "2          2023                 3          1210             275   319     17   \n",
      "3          2023                 3          1186             826    83      7   \n",
      "4          2023                 3          1184               1   254     14   \n",
      "\n",
      "   score  rank  \n",
      "0  84.08     1  \n",
      "1  77.51     2  \n",
      "2  73.08     3  \n",
      "3  70.96     4  \n",
      "4  69.21     5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# # Load the dataset\n",
    "# file_path = 'nirf_data_sets.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize a dictionary to store label encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Categorical columns to encode, including institute_id\n",
    "categorical_columns = ['ranking_category', 'institute_name', 'city', 'state',  'institute_id']\n",
    "\n",
    "# Encode categorical variables\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Save the label encoders for future use\n",
    "with open('label_encoders.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoders, le_file)\n",
    "\n",
    "print(\"Label encoders saved successfully.\")\n",
    "\n",
    "# Verify the encoded data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf109c8-c230-4d7b-8a77-34fc14bf51ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29a345a7-33d4-4df0-9241-6b8a6fce2af3",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be7f7234-c63e-4f1e-b650-1d4aa195ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'nirf_data_sets.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Distribution of Ranks\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['rank'], bins=30, kde=True)\n",
    "plt.title('Distribution of Ranks')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('static/images/rank_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Distribution of Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['score'], bins=30, kde=True)\n",
    "plt.title('Distribution of Scores')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('static/images/score_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Select only numeric columns for the correlation heatmap\n",
    "numeric_data = data.select_dtypes(include=[float, int])\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.savefig('static/images/correlation_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar chart of average scores by ranking category\n",
    "plt.figure(figsize=(12, 6))\n",
    "average_scores_by_category = data.groupby('ranking_category')['score'].mean().sort_values()\n",
    "sns.barplot(x=average_scores_by_category.index, y=average_scores_by_category.values)\n",
    "plt.title('Average Scores by Ranking Category')\n",
    "plt.xlabel('Ranking Category')\n",
    "plt.ylabel('Average Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('static/images/average_scores_by_category.png')\n",
    "plt.close()\n",
    "\n",
    "# Pie chart of institutes by state\n",
    "plt.figure(figsize=(12, 8))\n",
    "institutes_by_state = data['state'].value_counts()\n",
    "plt.pie(institutes_by_state, labels=institutes_by_state.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Institutes by State')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.savefig('static/images/institutes_by_state.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2f677-da89-41c9-b287-856c38d68382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15fa67db-8df0-4888-956f-520dce4d0c20",
   "metadata": {},
   "source": [
    "# Data Preparation for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c7fc7-dd64-44a2-88c0-c3c4c177f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513f661-064e-476b-b84f-6d9d436b4bb1",
   "metadata": {},
   "source": [
    "# FETURE SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2faf1f0b-24c3-47b1-aafd-4db2ee55e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features = data.drop(columns=['score'])  # Drop 'score' from features, keep 'rank' as a feature\n",
    "target = data['score']  # Set 'score' as the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff60987-55bd-4630-a610-4c6b3bc84d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "746ebf64-e0c4-4e1c-b8f0-52428614099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoders saved successfully.\n",
      "   ranking_year  ranking_category  institute_id  institute_name      city  \\\n",
      "0          2023         -1.039642      0.195979            1138 -1.089130   \n",
      "1          2023         -1.039642      0.190208             804  0.387806   \n",
      "2          2023         -1.039642      0.194055             275  0.898747   \n",
      "3          2023         -1.039642      0.147891             826 -0.985345   \n",
      "4          2023         -1.039642      0.144044               1  0.379823   \n",
      "\n",
      "      state  score      rank  \n",
      "0  0.910736  84.08 -1.237745  \n",
      "1 -0.519862  77.51 -1.212766  \n",
      "2 -0.189724  73.08 -1.187788  \n",
      "3 -1.290184  70.96 -1.162809  \n",
      "4 -0.519862  69.21 -1.137831  \n",
      "Scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "categorical_columns = ['ranking_category', 'institute_name', 'city', 'state', 'institute_id']\n",
    "\n",
    "\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "\n",
    "with open('label_encoders.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoders, le_file)\n",
    "print(\"Label encoders saved successfully.\")\n",
    "\n",
    "\n",
    "numerical_features = ['institute_id', 'city', 'state', 'ranking_category','rank']\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Scaler saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67cb95b6-bccf-4797-aab1-ef356502293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4322, 7)\n",
      "X_test shape: (1081, 7)\n",
      "y_train shape: (4322,)\n",
      "y_test shape: (1081,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset (assuming 'data' has already been label-encoded and standardized)\n",
    "file_path = 'nirf_data_sets.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove rows with missing target values\n",
    "data = data.dropna(subset=['score'])  # Drop rows where 'score' is NaN\n",
    "\n",
    "# Define the features and target variable\n",
    "features = data.drop(columns=['score'])  # Drop only 'score' from features, keep 'rank' as a feature if needed\n",
    "target = data['score']  # Set 'score' as the target variable\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the splits to confirm\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf6e031-1b44-4a67-9f05-df6525fc0cbc",
   "metadata": {},
   "source": [
    "# Model Building, Training, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f884ae-516d-49f2-922e-37debacb6eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved successfully.\n",
      "Mean Squared Error: 5.470610704525968\n",
      "R^2 Score: 0.9596662295070839\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "# file_path = 'nirf_data_sets.csv'\n",
    "# data = pd.read_csv(file_path)\n",
    "\n",
    "# Remove rows with missing target values\n",
    "data = data.dropna(subset=['score'])\n",
    "\n",
    "# Initialize a dictionary to store label encoders for each column\n",
    "label_encoders = {}\n",
    "\n",
    "# Categorical columns to encode\n",
    "categorical_columns = ['ranking_category', 'institute_id', 'institute_name', 'city', 'state']\n",
    "\n",
    "# Encode categorical variables\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Save the label encoders for future use\n",
    "with open('label_encoders.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoders, le_file)\n",
    "\n",
    "# Select numerical features to standardize\n",
    "numerical_features = ['institute_id', 'city', 'state', 'ranking_category', 'rank']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize numerical features\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"Scaler saved successfully.\")\n",
    "\n",
    "# Define the features and target variable\n",
    "features = data[numerical_features]\n",
    "target = data['score']  # Set 'score' as the target variable\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model without rounding predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Save the trained model for future use\n",
    "with open('model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83d5a5-3c37-4330-83ae-7f0a466dfd5e",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "324dcf20-1859-4ad9-91a2-c62af950487e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression - Mean Squared Error: 49.45520285000096\n",
      "LinearRegression - R^2 Score: 0.6353762113282391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the model\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Train the Linear Regression model\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_linear = linear_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "print(f'LinearRegression - Mean Squared Error: {mse_linear}')\n",
    "print(f'LinearRegression - R^2 Score: {r2_linear}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14a2c062-385b-447f-a950-e586abfc00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor - Mean Squared Error: 5.664113558178169\n",
      "GradientBoostingRegressor - R^2 Score: 0.9582395698322371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the model\n",
    "gbr = GradientBoostingRegressor(random_state=42, n_estimators=100)\n",
    "\n",
    "# Train the Gradient Boosting Regressor model\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gbr = gbr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_gbr = mean_squared_error(y_test, y_pred_gbr)\n",
    "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
    "\n",
    "print(f'GradientBoostingRegressor - Mean Squared Error: {mse_gbr}')\n",
    "print(f'GradientBoostingRegressor - R^2 Score: {r2_gbr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f02cd9-7221-416a-9d27-9b36aac40c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR - Mean Squared Error: 33.2038384652543\n",
      "SVR - R^2 Score: 0.7551944248137699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the model\n",
    "svr = SVR()\n",
    "\n",
    "# Train the Support Vector Regressor model\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(f'SVR - Mean Squared Error: {mse_svr}')\n",
    "print(f'SVR - R^2 Score: {r2_svr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df914596-10bd-4665-b505-ab8a0a315b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor - Mean Squared Error: 8.335681468316375\n",
      "DecisionTreeRegressor - R^2 Score: 0.9385426086036478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the model\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the Decision Tree Regressor model\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tree = tree_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f'DecisionTreeRegressor - Mean Squared Error: {mse_tree}')\n",
    "print(f'DecisionTreeRegressor - R^2 Score: {r2_tree}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49147b-906e-4a20-905e-2cfda1ee9886",
   "metadata": {},
   "source": [
    "# MODEL SAVING .PKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3f995fa-a238-4338-8fcb-c9d320eabe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "# Save the scaler to a file\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e58af6-a167-46d1-9b4e-02b26117fdb2",
   "metadata": {},
   "source": [
    "# FLASK BACKEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fa774-f10e-40a1-9cdc-2e441fbfef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model loaded successfully\n",
      "INFO:__main__:Scaler loaded successfully\n",
      "INFO:__main__:Label encoders loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5001\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import numpy as np\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load the trained model, scaler, and label encoders\n",
    "try:\n",
    "    with open('model.pkl', 'rb') as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "        app.logger.info(\"Model loaded successfully\")\n",
    "\n",
    "    with open('scaler.pkl', 'rb') as scaler_file:\n",
    "        scaler = joblib.load(scaler_file)\n",
    "        app.logger.info(\"Scaler loaded successfully\")\n",
    "\n",
    "    with open('label_encoders.pkl', 'rb') as le_file:\n",
    "        label_encoders = pickle.load(le_file)\n",
    "        app.logger.info(\"Label encoders loaded successfully\")\n",
    "except Exception as e:\n",
    "    app.logger.error(f\"Error loading model, scaler, or label encoders: {e}\")\n",
    "    raise e\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        app.logger.info('Received data: %s', data)\n",
    "\n",
    "        # Validate input data\n",
    "        if not data or 'features' not in data:\n",
    "            raise ValueError(\"Invalid input data: 'features' key not found.\")\n",
    "\n",
    "        features = data['features']\n",
    "        app.logger.info('Raw features: %s', features)\n",
    "\n",
    "        # Validate the length of features\n",
    "        if len(features) != 5:\n",
    "            raise ValueError(\"Invalid number of features provided.\")\n",
    "\n",
    "        # Extract and encode features\n",
    "        institute_id, city, state, ranking_category, rank = features\n",
    "\n",
    "        if institute_id not in label_encoders['institute_id'].classes_:\n",
    "            raise ValueError(f\"Institute ID '{institute_id}' not recognized.\")\n",
    "        if city not in label_encoders['city'].classes_:\n",
    "            raise ValueError(f\"City '{city}' not recognized.\")\n",
    "        if state not in label_encoders['state'].classes_:\n",
    "            raise ValueError(f\"State '{state}' not recognized.\")\n",
    "        if ranking_category not in label_encoders['ranking_category'].classes_:\n",
    "            raise ValueError(f\"Ranking Category '{ranking_category}' not recognized.\")\n",
    "\n",
    "        institute_id_encoded = label_encoders['institute_id'].transform([institute_id])[0]\n",
    "        city_encoded = label_encoders['city'].transform([city])[0]\n",
    "        state_encoded = label_encoders['state'].transform([state])[0]\n",
    "        ranking_category_encoded = label_encoders['ranking_category'].transform([ranking_category])[0]\n",
    "\n",
    "        # Ensure rank is an integer\n",
    "        try:\n",
    "            rank = int(rank)\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Rank should be an integer.\")\n",
    "\n",
    "        # Convert features to numpy array and reshape\n",
    "        features_array = np.array([institute_id_encoded, city_encoded, state_encoded, ranking_category_encoded, rank]).reshape(1, -1)\n",
    "        app.logger.info('Features array: %s', features_array)\n",
    "\n",
    "        # Standardize the features\n",
    "        features_scaled = scaler.transform(features_array)\n",
    "        app.logger.info('Transformed features: %s', features_scaled)\n",
    "\n",
    "        # Make prediction using loaded model\n",
    "        prediction = model.predict(features_scaled)\n",
    "        app.logger.info('Prediction: %s', prediction)\n",
    "\n",
    "        # Convert prediction to a more user-friendly format\n",
    "        rounded_prediction = round(prediction[0], 2)  # Round to 2 decimal places\n",
    "\n",
    "        return jsonify({'prediction': rounded_prediction})\n",
    "    except ValueError as ve:\n",
    "        error_message = f\"Value Error: {str(ve)}\"\n",
    "        app.logger.error(error_message)\n",
    "        return jsonify({'error': error_message}), 400\n",
    "    except Exception as e:\n",
    "        error_message = f\"Error during prediction: {str(e)}\"\n",
    "        app.logger.error(error_message)\n",
    "        return jsonify({'error': error_message}), 500\n",
    "\n",
    "@app.route('/analytics')\n",
    "def analytics():\n",
    "    return render_template('analytics.html')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True,port=5001,use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538eb56-4bc9-41c3-8322-3b5e283bc05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ed49e-2462-48e2-986b-db5fd3542e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dab1d-6152-4105-bc3b-9c178556e5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9416b347-173c-4901-870c-9c0aacfeb4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431591f-7e56-42ea-a870-0c217ca1fb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88ffe6-e1b7-4a2f-af2d-82883f1f5ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d8f39-ab24-4704-97f7-866d4b0d92b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdff7e7-af53-4b19-abf9-3c071f5faec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412e48d-9338-4556-85d9-035a990759a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
